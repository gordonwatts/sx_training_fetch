{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "774e89c3",
   "metadata": {},
   "source": [
    "# Test PHYSLITE Combination\n",
    "\n",
    "This notebook will test ideas for combining the calibrated values from PHYSLITE and the uncalibrated values from LLP1.\n",
    "\n",
    "* Should be faster than running calibrations of LLP1\n",
    "* Will be an in-memory test, which likely won't work for the full dataset.\n",
    "\n",
    "The datasets we'll use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9891dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_LLP1 = \"mc23_13p6TeV:mc23_13p6TeV.802746.Py8EG_Zprime2EJs_Ld20_rho40_pi10_Zp2600_l1.deriv.DAOD_LLP1.e8531_s4159_r15530_p6463\"\n",
    "did_PHYSLITE = \"mc23_13p6TeV:mc23_13p6TeV.802746.Py8EG_Zprime2EJs_Ld20_rho40_pi10_Zp2600_l1.deriv.DAOD_PHYSLITE.e8531_s4159_r15530_p6491\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2b6a16",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3321653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "from func_adl_servicex_xaodr25 import FuncADLQueryPHYSLITE\n",
    "from servicex import Sample, ServiceXSpec, dataset, deliver\n",
    "from servicex_analysis_utils import to_awk\n",
    "\n",
    "from calratio_training_data import RunConfig, fetch_training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ee51ba",
   "metadata": {},
   "source": [
    "## Fetching the data\n",
    "\n",
    "First the PHYSLITE data. We have to do this by hand, of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81dc5fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ea8d968a0f471db670e73526c44a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411807 * Momentum3D[\n",
      "    pt: float32,\n",
      "    eta: float32,\n",
      "    phi: float32,\n",
      "    runNumber: float32,\n",
      "    eventNumber: float32\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Define the base query\n",
    "base_query = FuncADLQueryPHYSLITE()\n",
    "\n",
    "# Query to fetch muons and MET\n",
    "query = base_query.Select(\n",
    "    lambda e: {\n",
    "        \"jets\": e.Jets().Where(lambda j: j.pt() >= 40 and abs(j.eta()) < 2.5),\n",
    "        \"event_info\": e.EventInfo(\"EventInfo\"),\n",
    "    }\n",
    ").Select(\n",
    "    lambda e: {\n",
    "        \"jet_pt\": e.jets.Select(lambda jet: jet.pt() / 1000.0),\n",
    "        \"jet_eta\": e.jets.Select(lambda jet: jet.eta()),\n",
    "        \"jet_phi\": e.jets.Select(lambda jet: jet.phi()),\n",
    "        \"run\": e.event_info.runNumber(),\n",
    "        \"event\": e.event_info.eventNumber(),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Fetch the data\n",
    "data = to_awk(\n",
    "    deliver(\n",
    "        ServiceXSpec(\n",
    "            Sample=[\n",
    "                Sample(\n",
    "                    Name=\"did_PHYSLITE\",\n",
    "                    Dataset=dataset.Rucio(did_PHYSLITE),\n",
    "                    Query=query,\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    ")[\"did_PHYSLITE\"]\n",
    "\n",
    "# Next, reformat it so it is per-jet, the way our training data is\n",
    "data_PHYSLITE = ak.values_astype(\n",
    "    ak.zip(\n",
    "        {\n",
    "            \"pt\": ak.flatten(data[\"jet_pt\"]),\n",
    "            \"eta\": ak.flatten(data[\"jet_eta\"]),\n",
    "            \"phi\": ak.flatten(data[\"jet_phi\"]),\n",
    "            \"runNumber\": ak.flatten(\n",
    "                ak.broadcast_arrays(data[\"run\"], data[\"jet_pt\"])[0], axis=1\n",
    "            ),\n",
    "            \"eventNumber\": ak.flatten(\n",
    "                ak.broadcast_arrays(data[\"event\"], data[\"jet_pt\"])[0], axis=1\n",
    "            ),\n",
    "        },\n",
    "        with_name=\"Momentum3D\",\n",
    "    ),\n",
    "    np.float32,\n",
    ")\n",
    "\n",
    "data_PHYSLITE.type.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11a74d2",
   "metadata": {},
   "source": [
    "And the training data\n",
    "\n",
    "* For this test we had to turn off the jet cleaning tool, as this version of LLP1 does not have the jet cleaning data. This was done by modifying the source code by hand (and hopefully not checking it in!).\n",
    "    * Modify the `training_query.py` `good_training_jet` function - comment out the call to `jet_clean_llp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df03b6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71b15fd4a20445395401095b73f5b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183797 * Momentum3D[\n",
      "    runNumber: uint32,\n",
      "    eventNumber: uint64,\n",
      "    pt: float32,\n",
      "    eta: float32,\n",
      "    phi: float32,\n",
      "    tracks: var * Momentum3D[\n",
      "        eta: float32,\n",
      "        phi: float32,\n",
      "        pt: float32,\n",
      "        vertex_nParticles: float32,\n",
      "        d0: float32,\n",
      "        z0: float32,\n",
      "        chiSquared: float32,\n",
      "        PixelShared: float32,\n",
      "        SCTShared: float32,\n",
      "        PixelHoles: float32,\n",
      "        SCTHoles: float32,\n",
      "        PixelHits: float32,\n",
      "        SCTHits: float32\n",
      "    ],\n",
      "    clusters: var * Momentum3D[\n",
      "        eta: float32,\n",
      "        phi: float32,\n",
      "        pt: float32,\n",
      "        l1hcal: float32,\n",
      "        l2hcal: float32,\n",
      "        l3hcal: float32,\n",
      "        l4hcal: float32,\n",
      "        l1ecal: float32,\n",
      "        l2ecal: float32,\n",
      "        l3ecal: float32,\n",
      "        l4ecal: float32,\n",
      "        time: float32\n",
      "    ],\n",
      "    msegs: var * {\n",
      "        etaPos: float32,\n",
      "        phiPos: float32,\n",
      "        etaDir: float32,\n",
      "        phiDir: float32,\n",
      "        t0: float32,\n",
      "        chiSquared: float32\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "data_LLP1 = fetch_training_data(did_LLP1, RunConfig(run_locally=False, ignore_cache=False))\n",
    "data_LLP1.type.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719454af",
   "metadata": {},
   "source": [
    "## Combining\n",
    "\n",
    "Now that we have `data_LLP1 and `data_PHYSLITE`, we need to combine the two event-by-event and jet-by-jet in the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6e47dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHYSLITE data fields:\n",
      "['pt', 'eta', 'phi', 'runNumber', 'eventNumber']\n",
      "PHYSLITE data length: 411807\n",
      "\n",
      "LLP1 data fields:\n",
      "['runNumber', 'eventNumber', 'pt', 'eta', 'phi', 'tracks', 'clusters', 'msegs']\n",
      "LLP1 data length: 183797\n",
      "\n",
      "First few PHYSLITE jets:\n",
      "[{pt: 613, eta: 0.234, phi: -0.401, runNumber: 4.5e+05, ...}, {...}, {...}]\n",
      "\n",
      "First few LLP1 jets:\n",
      "[{runNumber: 450000, eventNumber: 38001, pt: 1.09e+03, eta: 0.0725, ...}, ...]\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the structure of both datasets\n",
    "print(\"PHYSLITE data fields:\")\n",
    "print(data_PHYSLITE.fields)\n",
    "print(f\"PHYSLITE data length: {len(data_PHYSLITE)}\")\n",
    "print(\"\\nLLP1 data fields:\")\n",
    "print(data_LLP1.fields)\n",
    "print(f\"LLP1 data length: {len(data_LLP1)}\")\n",
    "\n",
    "# Show a few examples\n",
    "print(\"\\nFirst few PHYSLITE jets:\")\n",
    "print(data_PHYSLITE[:3])\n",
    "print(\"\\nFirst few LLP1 jets:\")\n",
    "print(data_LLP1[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85244747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimized jet matching...\n",
      "Optimized matching between 411807 PHYSLITE jets and 183797 LLP1 jets...\n",
      "Finding common events...\n",
      "Found 30000 common events\n",
      "PHYSLITE jets in common events: 411807\n",
      "LLP1 jets in common events: 183797\n",
      "Matching jets within events...\n",
      "Processed 1000/30000 events\n",
      "Processed 2000/30000 events\n",
      "Processed 3000/30000 events\n",
      "Processed 4000/30000 events\n",
      "Processed 5000/30000 events\n",
      "Processed 6000/30000 events\n",
      "Processed 7000/30000 events\n",
      "Processed 8000/30000 events\n",
      "Processed 9000/30000 events\n",
      "Processed 10000/30000 events\n",
      "Processed 11000/30000 events\n",
      "Processed 12000/30000 events\n",
      "Processed 13000/30000 events\n",
      "Processed 14000/30000 events\n",
      "Processed 15000/30000 events\n",
      "Processed 16000/30000 events\n",
      "Processed 17000/30000 events\n",
      "Processed 18000/30000 events\n",
      "Processed 19000/30000 events\n",
      "Processed 20000/30000 events\n",
      "Processed 21000/30000 events\n",
      "Processed 22000/30000 events\n",
      "Processed 23000/30000 events\n",
      "Processed 24000/30000 events\n",
      "Processed 25000/30000 events\n",
      "Processed 26000/30000 events\n",
      "Processed 27000/30000 events\n",
      "Processed 28000/30000 events\n",
      "Processed 29000/30000 events\n",
      "Processed 30000/30000 events\n",
      "Found 188311 total matched jets\n",
      "Creating basic combined dataset...\n",
      "Adding nested LLP1 data...\n",
      "Combined dataset has 188311 jets\n",
      "Mean delta R: 0.0456\n",
      "Max delta R: 0.4000\n",
      "PT calibration factor - mean: 0.960, std: 0.224\n"
     ]
    }
   ],
   "source": [
    "def match_jets_optimized(physlite_data, llp1_data, delta_r_threshold=0.4):\n",
    "    \"\"\"\n",
    "    Optimized jet matching using vectorized operations where possible.\n",
    "    \n",
    "    Args:\n",
    "        physlite_data: PHYSLITE jet data with calibrated pt, eta, phi\n",
    "        llp1_data: LLP1 jet data with additional information (tracks, clusters, msegs)\n",
    "        delta_r_threshold: Maximum delta R for jet matching\n",
    "    \n",
    "    Returns:\n",
    "        Combined dataset with PHYSLITE kinematics and LLP1 additional information\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Optimized matching between {len(physlite_data)} PHYSLITE jets and {len(llp1_data)} LLP1 jets...\")\n",
    "    \n",
    "    # Convert to numpy for faster operations\n",
    "    physlite_run = ak.to_numpy(physlite_data.runNumber).astype(np.int64)\n",
    "    physlite_event = ak.to_numpy(physlite_data.eventNumber).astype(np.int64)\n",
    "    physlite_eta = ak.to_numpy(physlite_data.eta).astype(np.float32)\n",
    "    physlite_phi = ak.to_numpy(physlite_data.phi).astype(np.float32)\n",
    "    \n",
    "    llp1_run = ak.to_numpy(llp1_data.runNumber).astype(np.int64) \n",
    "    llp1_event = ak.to_numpy(llp1_data.eventNumber).astype(np.int64)\n",
    "    llp1_eta = ak.to_numpy(llp1_data.eta).astype(np.float32)\n",
    "    llp1_phi = ak.to_numpy(llp1_data.phi).astype(np.float32)\n",
    "    \n",
    "    # Create event keys\n",
    "    physlite_event_keys = physlite_run * 1000000 + physlite_event\n",
    "    llp1_event_keys = llp1_run * 1000000 + llp1_event\n",
    "    \n",
    "    print(\"Finding common events...\")\n",
    "    \n",
    "    # Find common events efficiently\n",
    "    common_events = np.intersect1d(physlite_event_keys, llp1_event_keys)\n",
    "    print(f\"Found {len(common_events)} common events\")\n",
    "    \n",
    "    if len(common_events) == 0:\n",
    "        print(\"No common events!\")\n",
    "        return None\n",
    "    \n",
    "    # Create masks for jets in common events\n",
    "    physlite_mask = np.isin(physlite_event_keys, common_events)\n",
    "    llp1_mask = np.isin(llp1_event_keys, common_events)\n",
    "    \n",
    "    print(f\"PHYSLITE jets in common events: {np.sum(physlite_mask)}\")\n",
    "    print(f\"LLP1 jets in common events: {np.sum(llp1_mask)}\")\n",
    "    \n",
    "    # Extract jets in common events\n",
    "    physlite_filtered_idx = np.where(physlite_mask)[0]\n",
    "    llp1_filtered_idx = np.where(llp1_mask)[0]\n",
    "    \n",
    "    physlite_filtered_events = physlite_event_keys[physlite_mask]\n",
    "    llp1_filtered_events = llp1_event_keys[llp1_mask]\n",
    "    physlite_filtered_eta = physlite_eta[physlite_mask]\n",
    "    physlite_filtered_phi = physlite_phi[physlite_mask]\n",
    "    llp1_filtered_eta = llp1_eta[llp1_mask]\n",
    "    llp1_filtered_phi = llp1_phi[llp1_mask]\n",
    "    \n",
    "    print(\"Matching jets within events...\")\n",
    "    \n",
    "    # Group by event and match jets\n",
    "    matched_physlite_idx = []\n",
    "    matched_llp1_idx = []\n",
    "    match_delta_r = []\n",
    "    \n",
    "    # Process each common event\n",
    "    unique_events = np.unique(common_events)\n",
    "    \n",
    "    for i, event_key in enumerate(unique_events):\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(unique_events)} events\")\n",
    "            \n",
    "        # Get jets for this event\n",
    "        physlite_event_mask = physlite_filtered_events == event_key\n",
    "        llp1_event_mask = llp1_filtered_events == event_key\n",
    "        \n",
    "        if not np.any(physlite_event_mask) or not np.any(llp1_event_mask):\n",
    "            continue\n",
    "            \n",
    "        event_physlite_idx = physlite_filtered_idx[physlite_event_mask]\n",
    "        event_llp1_idx = llp1_filtered_idx[llp1_event_mask]\n",
    "        \n",
    "        event_physlite_eta = physlite_filtered_eta[physlite_event_mask]\n",
    "        event_physlite_phi = physlite_filtered_phi[physlite_event_mask]\n",
    "        event_llp1_eta = llp1_filtered_eta[llp1_event_mask]\n",
    "        event_llp1_phi = llp1_filtered_phi[llp1_event_mask]\n",
    "        \n",
    "        # Calculate distance matrix for this event\n",
    "        delta_eta = event_physlite_eta[:, np.newaxis] - event_llp1_eta[np.newaxis, :]\n",
    "        delta_phi = event_physlite_phi[:, np.newaxis] - event_llp1_phi[np.newaxis, :]\n",
    "        \n",
    "        # Handle phi wraparound\n",
    "        delta_phi = np.where(np.abs(delta_phi) > np.pi,\n",
    "                           delta_phi - 2*np.pi*np.sign(delta_phi),\n",
    "                           delta_phi)\n",
    "        \n",
    "        # Calculate delta R\n",
    "        delta_r = np.sqrt(delta_eta**2 + delta_phi**2)\n",
    "        \n",
    "        # Find best matches for each PHYSLITE jet\n",
    "        min_delta_r = np.min(delta_r, axis=1)\n",
    "        best_llp1_idx = np.argmin(delta_r, axis=1)\n",
    "        \n",
    "        # Apply threshold\n",
    "        good_matches = min_delta_r < delta_r_threshold\n",
    "        \n",
    "        if np.any(good_matches):\n",
    "            matched_physlite_idx.extend(event_physlite_idx[good_matches])\n",
    "            matched_llp1_idx.extend(event_llp1_idx[best_llp1_idx[good_matches]])\n",
    "            match_delta_r.extend(min_delta_r[good_matches])\n",
    "    \n",
    "    print(f\"Found {len(matched_physlite_idx)} total matched jets\")\n",
    "    \n",
    "    if len(matched_physlite_idx) == 0:\n",
    "        print(\"No jets pass matching criteria!\")\n",
    "        return None\n",
    "    \n",
    "    # Create basic dataset first to avoid broadcasting issues\n",
    "    print(\"Creating basic combined dataset...\")\n",
    "    combined_data = ak.zip({\n",
    "        # Use calibrated kinematics from PHYSLITE\n",
    "        \"pt\": physlite_data.pt[matched_physlite_idx],\n",
    "        \"eta\": physlite_data.eta[matched_physlite_idx], \n",
    "        \"phi\": physlite_data.phi[matched_physlite_idx],\n",
    "        \n",
    "        # Use original (uncalibrated) kinematics from LLP1 for reference\n",
    "        \"pt_uncalib\": llp1_data.pt[matched_llp1_idx],\n",
    "        \"eta_uncalib\": llp1_data.eta[matched_llp1_idx],\n",
    "        \"phi_uncalib\": llp1_data.phi[matched_llp1_idx],\n",
    "        \n",
    "        # Event information\n",
    "        \"runNumber\": physlite_data.runNumber[matched_physlite_idx],\n",
    "        \"eventNumber\": physlite_data.eventNumber[matched_physlite_idx],\n",
    "        \n",
    "        # Matching quality\n",
    "        \"delta_r_match\": ak.Array(match_delta_r),\n",
    "    })\n",
    "    \n",
    "    print(\"Adding nested LLP1 data...\")\n",
    "    # Add the nested fields separately to avoid broadcasting issues\n",
    "    combined_data = ak.with_field(combined_data, llp1_data.tracks[matched_llp1_idx], \"tracks\")\n",
    "    combined_data = ak.with_field(combined_data, llp1_data.clusters[matched_llp1_idx], \"clusters\")\n",
    "    combined_data = ak.with_field(combined_data, llp1_data.msegs[matched_llp1_idx], \"msegs\")\n",
    "    \n",
    "    print(f\"Combined dataset has {len(combined_data)} jets\")\n",
    "    print(f\"Mean delta R: {ak.mean(combined_data.delta_r_match):.4f}\")\n",
    "    print(f\"Max delta R: {ak.max(combined_data.delta_r_match):.4f}\")\n",
    "    \n",
    "    # Show pt calibration factor distribution\n",
    "    calib_factor = combined_data.pt / combined_data.pt_uncalib\n",
    "    print(f\"PT calibration factor - mean: {ak.mean(calib_factor):.3f}, std: {ak.std(calib_factor):.3f}\")\n",
    "    \n",
    "    return combined_data\n",
    "\n",
    "# Perform the optimized matching\n",
    "print(\"Starting optimized jet matching...\")\n",
    "combined_jets = match_jets_optimized(data_PHYSLITE, data_LLP1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f71f79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== JET MATCHING RESULTS ===\n",
      "Successfully matched 188,311 jets\n",
      "Available fields: ['pt', 'eta', 'phi', 'pt_uncalib', 'eta_uncalib', 'phi_uncalib', 'runNumber', 'eventNumber', 'delta_r_match', 'tracks', 'clusters', 'msegs']\n",
      "\n",
      "=== MATCHING QUALITY ===\n",
      "Delta R statistics:\n",
      "  Mean: 0.0456\n",
      "  Median: 0.0196\n",
      "  Std: 0.0705\n",
      "  Max: 0.4000\n",
      "\n",
      "=== CALIBRATION FACTORS ===\n",
      "PT calibration (calibrated/uncalibrated):\n",
      "  Mean: 0.9595\n",
      "  Median: 0.9968\n",
      "  Std: 0.2235\n",
      "Eta difference (calibrated - uncalibrated):\n",
      "  Mean: -0.000003\n",
      "  Std: 0.057810\n",
      "Phi difference (calibrated - uncalibrated):\n",
      "  Mean: 0.000401\n",
      "  Std: 0.421882\n",
      "\n",
      "=== ADDITIONAL DATA AVAILABILITY ===\n",
      "Tracks per jet - mean: 2.6\n",
      "Clusters per jet - mean: 0.0\n",
      "Msegs per jet - mean: 5.4\n",
      "\n",
      "=== EXAMPLE JETS ===\n",
      "Jet 1:\n",
      "  Event: Run 450000.0, Event 30001.0\n",
      "  PT: 267.6 → 298.9 GeV (factor: 1.117)\n",
      "  Eta: -1.2392 → -1.2348\n",
      "  Phi: -0.4424 → -0.4539\n",
      "  Delta R: 0.0124\n",
      "  Tracks: 10, Clusters: 0, Msegs: 1\n",
      "\n",
      "Jet 2:\n",
      "  Event: Run 450000.0, Event 30001.0\n",
      "  PT: 200.9 → 204.2 GeV (factor: 1.017)\n",
      "  Eta: 1.0863 → 1.0937\n",
      "  Phi: -2.6471 → -2.6610\n",
      "  Delta R: 0.0157\n",
      "  Tracks: 1, Clusters: 0, Msegs: 0\n",
      "\n",
      "Jet 3:\n",
      "  Event: Run 450000.0, Event 30001.0\n",
      "  PT: 166.0 → 183.6 GeV (factor: 1.106)\n",
      "  Eta: -0.7308 → -0.7501\n",
      "  Phi: 1.5158 → 1.5430\n",
      "  Delta R: 0.0334\n",
      "  Tracks: 3, Clusters: 0, Msegs: 4\n",
      "\n",
      "SUCCESS: Jet matching complete! 🎉\n",
      "You now have a combined dataset with:\n",
      "- Calibrated pt, eta, phi from PHYSLITE\n",
      "- Tracks, clusters, and msegs from LLP1\n",
      "- All properly matched by event and proximity in eta-phi space\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the results\n",
    "print(\"=== JET MATCHING RESULTS ===\")\n",
    "print(f\"Successfully matched {len(combined_jets):,} jets\")\n",
    "print(f\"Available fields: {combined_jets.fields}\")\n",
    "print()\n",
    "\n",
    "print(\"=== MATCHING QUALITY ===\")\n",
    "print(f\"Delta R statistics:\")\n",
    "print(f\"  Mean: {ak.mean(combined_jets.delta_r_match):.4f}\")\n",
    "print(f\"  Median: {np.median(ak.to_numpy(combined_jets.delta_r_match)):.4f}\") \n",
    "print(f\"  Std: {ak.std(combined_jets.delta_r_match):.4f}\")\n",
    "print(f\"  Max: {ak.max(combined_jets.delta_r_match):.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"=== CALIBRATION FACTORS ===\")\n",
    "pt_calib = combined_jets.pt / combined_jets.pt_uncalib\n",
    "eta_diff = combined_jets.eta - combined_jets.eta_uncalib\n",
    "phi_diff = combined_jets.phi - combined_jets.phi_uncalib\n",
    "\n",
    "print(f\"PT calibration (calibrated/uncalibrated):\")\n",
    "print(f\"  Mean: {ak.mean(pt_calib):.4f}\")\n",
    "print(f\"  Median: {np.median(ak.to_numpy(pt_calib)):.4f}\")\n",
    "print(f\"  Std: {ak.std(pt_calib):.4f}\")\n",
    "\n",
    "print(f\"Eta difference (calibrated - uncalibrated):\")\n",
    "print(f\"  Mean: {ak.mean(eta_diff):.6f}\")\n",
    "print(f\"  Std: {ak.std(eta_diff):.6f}\")\n",
    "\n",
    "print(f\"Phi difference (calibrated - uncalibrated):\")  \n",
    "print(f\"  Mean: {ak.mean(phi_diff):.6f}\")\n",
    "print(f\"  Std: {ak.std(phi_diff):.6f}\")\n",
    "print()\n",
    "\n",
    "print(\"=== ADDITIONAL DATA AVAILABILITY ===\")\n",
    "print(f\"Tracks per jet - mean: {ak.mean(ak.num(combined_jets.tracks)):.1f}\")\n",
    "print(f\"Clusters per jet - mean: {ak.mean(ak.num(combined_jets.clusters)):.1f}\")\n",
    "print(f\"Msegs per jet - mean: {ak.mean(ak.num(combined_jets.msegs)):.1f}\")\n",
    "print()\n",
    "\n",
    "print(\"=== EXAMPLE JETS ===\")\n",
    "for i in range(min(3, len(combined_jets))):\n",
    "    print(f\"Jet {i+1}:\")\n",
    "    print(f\"  Event: Run {combined_jets.runNumber[i]}, Event {combined_jets.eventNumber[i]}\")\n",
    "    print(f\"  PT: {combined_jets.pt_uncalib[i]:.1f} → {combined_jets.pt[i]:.1f} GeV (factor: {combined_jets.pt[i]/combined_jets.pt_uncalib[i]:.3f})\")\n",
    "    print(f\"  Eta: {combined_jets.eta_uncalib[i]:.4f} → {combined_jets.eta[i]:.4f}\")\n",
    "    print(f\"  Phi: {combined_jets.phi_uncalib[i]:.4f} → {combined_jets.phi[i]:.4f}\")\n",
    "    print(f\"  Delta R: {combined_jets.delta_r_match[i]:.4f}\")\n",
    "    print(f\"  Tracks: {len(combined_jets.tracks[i])}, Clusters: {len(combined_jets.clusters[i])}, Msegs: {len(combined_jets.msegs[i])}\")\n",
    "    print()\n",
    "\n",
    "print(\"SUCCESS: Jet matching complete! 🎉\")\n",
    "print(\"You now have a combined dataset with:\")\n",
    "print(\"- Calibrated pt, eta, phi from PHYSLITE\")\n",
    "print(\"- Tracks, clusters, and msegs from LLP1\") \n",
    "print(\"- All properly matched by event and proximity in eta-phi space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61811685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHYSLITE run/event ranges:\n",
      "Run range: 450000.0 - 450000.0\n",
      "Event range: 30001.0 - 60000.0\n",
      "\n",
      "LLP1 run/event ranges:\n",
      "Run range: 450000 - 450000\n",
      "Event range: 30001 - 60000\n",
      "\n",
      "Common runs: [np.float32(450000.0)]\n",
      "PHYSLITE runs: [450000.]\n",
      "LLP1 runs: [450000]\n",
      "\n",
      "First 10 PHYSLITE events (run, event):\n",
      "  (450000.0, 32060.0)\n",
      "  (450000.0, 32060.0)\n",
      "  (450000.0, 32060.0)\n",
      "  (450000.0, 32060.0)\n",
      "  (450000.0, 32060.0)\n",
      "  (450000.0, 32060.0)\n",
      "  (450000.0, 32060.0)\n",
      "  (450000.0, 32060.0)\n",
      "  (450000.0, 32060.0)\n",
      "  (450000.0, 32060.0)\n",
      "\n",
      "First 10 LLP1 events (run, event):\n",
      "  (450000, 38001)\n",
      "  (450000, 38001)\n",
      "  (450000, 38001)\n",
      "  (450000, 38001)\n",
      "  (450000, 38001)\n",
      "  (450000, 38001)\n",
      "  (450000, 38001)\n",
      "  (450000, 38009)\n",
      "  (450000, 38009)\n",
      "  (450000, 38009)\n",
      "\n",
      "Number of common events: 30000\n",
      "First few common events: [(450000.0, 41535.0), (450000.0, 35119.0), (450000.0, 57750.0), (450000.0, 51334.0), (450000.0, 44918.0)]\n"
     ]
    }
   ],
   "source": [
    "# Let's debug why no matches were found\n",
    "print(\"PHYSLITE run/event ranges:\")\n",
    "print(f\"Run range: {ak.min(data_PHYSLITE.runNumber)} - {ak.max(data_PHYSLITE.runNumber)}\")\n",
    "print(f\"Event range: {ak.min(data_PHYSLITE.eventNumber)} - {ak.max(data_PHYSLITE.eventNumber)}\")\n",
    "\n",
    "print(\"\\nLLP1 run/event ranges:\")\n",
    "print(f\"Run range: {ak.min(data_LLP1.runNumber)} - {ak.max(data_LLP1.runNumber)}\")\n",
    "print(f\"Event range: {ak.min(data_LLP1.eventNumber)} - {ak.max(data_LLP1.eventNumber)}\")\n",
    "\n",
    "# Check for any overlapping runs using numpy for unique\n",
    "physlite_runs = np.unique(ak.to_numpy(data_PHYSLITE.runNumber))\n",
    "llp1_runs = np.unique(ak.to_numpy(data_LLP1.runNumber))\n",
    "common_runs = [r for r in physlite_runs if r in llp1_runs]\n",
    "print(f\"\\nCommon runs: {common_runs}\")\n",
    "print(f\"PHYSLITE runs: {physlite_runs}\")\n",
    "print(f\"LLP1 runs: {llp1_runs}\")\n",
    "\n",
    "# Let's also check some specific events\n",
    "print(f\"\\nFirst 10 PHYSLITE events (run, event):\")\n",
    "for i in range(min(10, len(data_PHYSLITE))):\n",
    "    print(f\"  ({data_PHYSLITE.runNumber[i]}, {data_PHYSLITE.eventNumber[i]})\")\n",
    "\n",
    "print(f\"\\nFirst 10 LLP1 events (run, event):\")  \n",
    "for i in range(min(10, len(data_LLP1))):\n",
    "    print(f\"  ({data_LLP1.runNumber[i]}, {data_LLP1.eventNumber[i]})\")\n",
    "\n",
    "# Check if there are any events in common at all\n",
    "physlite_events = set()\n",
    "for i in range(len(data_PHYSLITE)):\n",
    "    physlite_events.add((float(data_PHYSLITE.runNumber[i]), float(data_PHYSLITE.eventNumber[i])))\n",
    "\n",
    "llp1_events = set()\n",
    "for i in range(len(data_LLP1)):\n",
    "    llp1_events.add((float(data_LLP1.runNumber[i]), float(data_LLP1.eventNumber[i])))\n",
    "\n",
    "common_events = physlite_events.intersection(llp1_events)\n",
    "print(f\"\\nNumber of common events: {len(common_events)}\")\n",
    "if len(common_events) > 0:\n",
    "    print(f\"First few common events: {list(common_events)[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f08fb7b",
   "metadata": {},
   "source": [
    "## Combining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da64b752",
   "metadata": {},
   "source": [
    "This combination is done in memory to test out the basic mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6711166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_event(d):\n",
    "    key = ak.zip({\"run\": d.runNumber, \"evt\":d.eventNumber}, depth_limit=1)\n",
    "    run_ordered = ak.argsort(key.run, stable=True)\n",
    "    run_runs = ak.run_lengths(key[run_ordered].run)\n",
    "    key_by_event = ak.unflatten(key[run_ordered], run_runs)\n",
    "\n",
    "    event_ordered = ak.argsort(key_by_event.evt, stable=True, axis=-1)\n",
    "    event_runs = ak.run_lengths(key_by_event[event_ordered].evt)\n",
    "    group_event = ak.unflatten(key_by_event[event_ordered], ak.flatten(event_runs), axis=-1)\n",
    "\n",
    "    return group_event\n",
    "\n",
    "group_event_PHYSLITE = group_by_event(data_PHYSLITE)\n",
    "group_event_LLP1 = group_by_event(data_LLP1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e970fb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[450000,\n",
       " 450000,\n",
       " 450000,\n",
       " 450000,\n",
       " 450000,\n",
       " 450000,\n",
       " 450000,\n",
       " 450000,\n",
       " 450000]\n",
       "--------\n",
       "backend: cpu\n",
       "nbytes: 735.3 kB\n",
       "type: 9 * uint32</pre>"
      ],
      "text/plain": [
       "<Array [450000, 450000, 450000, ..., 450000, 450000, 450000] type='9 * uint32'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_event_LLP1[:].run[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9799b152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[[30001],\n",
       " [30002],\n",
       " [30003],\n",
       " [30004],\n",
       " [30005],\n",
       " [30006],\n",
       " [30007],\n",
       " [30008],\n",
       " [30009],\n",
       " [30010],\n",
       " ...,\n",
       " [59992],\n",
       " [59993],\n",
       " [59994],\n",
       " [59995],\n",
       " [59996],\n",
       " [59997],\n",
       " [59998],\n",
       " [59999],\n",
       " [60000]]\n",
       "---------\n",
       "backend: cpu\n",
       "nbytes: 270.0 kB\n",
       "type: 30000 * 1 * ?uint64</pre>"
      ],
      "text/plain": [
       "<Array [[30001], [30002], ..., [59999], [60000]] type='30000 * 1 * ?uint64'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.max(group_event_LLP1[0].evt, keepdims=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee6a225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
